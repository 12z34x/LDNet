# cctrans之前测试
方案0：尝试使用非预训练的ViT做backbone——效果非常差(MAE=50,MSE=113)

方案1：原图直接resize到384*384+预训练的base_384+线性回归一个数（smoothL1损失）——效果很差(MAE=18,MSE=37)

分析：方案1效果差，原图尺寸过小，损失太多细节。

方案2：原图resize到1536*1536+预训练的GhostNet前2个stage（下采样）+RFB（对齐通道）+预训练的base_384+线性回归一个数（smoothL1损失）——效果很差(MAE=22,MSE=41)

分析：方案2效果还是差，考虑到patch_embed操作中有大卷积，其接在两次下采样后令特征过于模糊，局部信息弱化；仅用人数构建损失函数难以较好地代表任务目标，模型无法较好地学习人头。

方案3：原图resize到1536*1536+预训练的GhostNet前2个stage+1*1卷积（对齐通道）+预训练的base_384+直接reshape特征得密度图（交叉熵损失)——效果很差(MAE=23,MSE=37)

分析：方案3效果还是差，考虑到transformer计算时丢失了维度上的位置信息。

方案4：原图resize到1536*1536+预训练的GhostNet前2个stage+1*1卷积+将patch_embed中的大卷积替换为手工reshape(提升精细度，可加入块内pos信息来强化局部信息)+预训练的base_384+直接reshape特征得密度图（交叉熵损失)——效果非常差(MAE=37,MSE=50)

分析：方案4效果更差，考虑到transformer不仅计算时丢失了维度上的位置信息，还因缺乏卷积而缺少拟合能力，但过多卷积确实又会损失太多细节。

方案5：原图resize到896*896+预训练的GhostNet前2个stage+link卷积+预训练的PVT_large224四个阶段（batch_size*49*512）+线性回归一个数（smoothL1损失）——效果很差(MAE=21,MSE=29)

分析：方案5效果很差，但MSE指标相对较好，考虑到逐级下采样更能捕捉局部的人头特征；仅用人数构建损失函数难以较好地代表任务目标，模型无法较好地学习人头。

方案6：原图resize到896*896+预训练的GhostNet前2个stage+RFB卷积+预训练的PVT_large224第一阶段（batch_size*64*56*56）+RFB卷积（压缩通道为16）+直接reshape特征得密度图（交叉熵损失)——效果很差(MAE=23,MSE=41)

分析：stage1过短，特征提取不足。

方案7：原图resize到896*896+预训练的GhostNet前2个stage+link卷积+预训练的SwinT_base224+直接reshape特征得密度图（交叉熵损失)——效果很差(MAE=18,MSE=29)

分析：最后特征图尺寸过小，维度上的位置信息难以保留。

方案8：原图resize到786*786+预训练的SwinT_base384第2、3个stage做FPN（attn_mask.repeat）+两次上采样（无BN与激活函数）+密度头得密度图（交叉熵损失)——效果一般(MAE=9.5,MSE=14.5)

分析：局部信息可能不够用充分。

方案9：原图resize到768*768+预训练的SwinT_base384（attn_mask.repeat）取前3个stage（用1*3卷积压缩通道为1/3之后）做FPN+一次上采样+密度头（3*3卷积+普通BN+ReLU+1*1卷积）得密度图（交叉熵损失)+adamw——效果一般(MAE=9.7,MSE=14.7)

分析：可能SGD的效果更适合人群计数任务（大多文章依旧使用SGD）。

方案10：原图resize到768*768+预训练的SwinT_base384金字塔前三个stage或前2个stage做FPN+做0次或1次上采样+密度头得密度图（交叉熵损失)——待尝试
